{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyeed import Pyeed\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "from pyeed.analysis.ontology_loading import OntologyAdapter\n",
    "from pyeed.analysis.embedding_analysis import EmbeddingTool\n",
    "from pyeed.analysis.sequence_alignment import PairwiseAligner\n",
    "from pyeed.analysis.mutation_detection import MutationDetection\n",
    "from pyeed.analysis.standard_numbering import StandardNumbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = EmbeddingTool()\n",
    "pa = PairwiseAligner()\n",
    "md = MutationDetection()\n",
    "sn = StandardNumbering(name='TEM_test_standard_numbering')\n",
    "oa = OntologyAdapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¡ Connected to database.\n"
     ]
    }
   ],
   "source": [
    "uri = \"bolt://127.0.0.1:1123\"\n",
    "user = \"neo4j\"\n",
    "password = \"niklasonlytems\"\n",
    "\n",
    "eedb = Pyeed(uri, user=user, password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 18:32:12,718 - INFO - Database stats: {'nodes': 9052, 'relationships': 141302}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the connection url is bolt://neo4j:niklasonlytems@127.0.0.1:1123\n",
      "Loaded /home/nab/Niklas/pyeed/src/pyeed/model.py\n",
      "Connecting to bolt://neo4j:niklasonlytems@127.0.0.1:1123\n",
      "Setting up indexes and constraints...\n",
      "\n",
      "Found model.StrictStructuredNode\n",
      " ! Skipping class model.StrictStructuredNode is abstract\n",
      "Found model.Organism\n",
      " + Creating node unique constraint for taxonomy_id on label Organism for class model.Organism\n",
      "{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=15, name='constraint_unique_Organism_taxonomy_id', type='UNIQUENESS', schema=(:Organism {taxonomy_id}), ownedIndex=14 )'.}\n",
      "Found model.Site\n",
      " + Creating node unique constraint for site_id on label Site for class model.Site\n",
      "{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=10, name='constraint_unique_Site_site_id', type='UNIQUENESS', schema=(:Site {site_id}), ownedIndex=9 )'.}\n",
      "Found model.Region\n",
      " + Creating node unique constraint for region_id on label Region for class model.Region\n",
      "{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=18, name='constraint_unique_Region_region_id', type='UNIQUENESS', schema=(:Region {region_id}), ownedIndex=17 )'.}\n",
      "Found model.CatalyticActivity\n",
      " + Creating node unique constraint for catalytic_id on label CatalyticActivity for class model.CatalyticActivity\n",
      "{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=20, name='constraint_unique_CatalyticActivity_catalytic_id', type='UNIQUENESS', schema=(:CatalyticActivity {catalytic_id}), ownedIndex=19 )'.}\n",
      "Found model.StandardNumbering\n",
      "Found model.GOAnnotation\n",
      " + Creating node unique constraint for go_id on label GOAnnotation for class model.GOAnnotation\n",
      "{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=4, name='constraint_unique_GOAnnotation_go_id', type='UNIQUENESS', schema=(:GOAnnotation {go_id}), ownedIndex=3 )'.}\n",
      "Found model.Protein\n",
      " + Creating node unique constraint for accession_id on label Protein for class model.Protein\n",
      "{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=12, name='constraint_unique_Protein_accession_id', type='UNIQUENESS', schema=(:Protein {accession_id}), ownedIndex=11 )'.}\n",
      " + Creating vector index for embedding on label Protein for class model.Protein\n",
      "{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent index already exists, 'Index( id=7, name='vector_index_Protein_embedding', type='VECTOR', schema=(:Protein {embedding}), indexProvider='vector-2.0' )'.}\n",
      "Found model.DNA\n",
      " + Creating node unique constraint for accession_id on label DNA for class model.DNA\n",
      "{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=5, name='constraint_unique_DNA_accession_id', type='UNIQUENESS', schema=(:DNA {accession_id}), ownedIndex=8 )'.}\n",
      " + Creating vector index for embedding on label DNA for class model.DNA\n",
      "{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent index already exists, 'Index( id=6, name='vector_index_DNA_embedding', type='VECTOR', schema=(:DNA {embedding}), indexProvider='vector-2.0' )'.}\n",
      "Found model.OntologyObject\n",
      " + Creating node unique constraint for name on label OntologyObject for class model.OntologyObject\n",
      "{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=13, name='constraint_unique_OntologyObject_name', type='UNIQUENESS', schema=(:OntologyObject {name}), ownedIndex=16 )'.}\n",
      "\n",
      "Finished 10 classes.\n",
      "âœ… Databse constraints and indexes set up according to Pyeed Graph Object Model.\n"
     ]
    }
   ],
   "source": [
    "# For testing purposes, we will wipe the database and remove all constraints\n",
    "# eedb.db.wipe_database(date='2024-12-13')\n",
    "# eedb.db.remove_db_constraints(user=user, password=password)\n",
    "\n",
    "# DB connector is an attribute of the Pyeed object, type `DatabaseConnector`\n",
    "LOGGER.info(f\"Database stats: {eedb.db.stats()}\")\n",
    "\n",
    "# The first time the pyeed database is initialized, we need to create the constraints which are defined in the pyeed graph model\n",
    "eedb.db.initialize_db_constraints(user=user, password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 protein_name phenotype    protein_id protein_id_database\n",
      "0           0        TEM-1        2b      AAP20891          AAP20891.1\n",
      "1           1        TEM-2        2b      CAJ85677          CAJ85677.1\n",
      "2           2        TEM-3       2be      SAQ02853          SAQ02853.1\n",
      "3           3        TEM-4       2be      CDR98216          CDR98216.1\n",
      "4           4        TEM-5       2be  WP_109963600      WP_109963600.1\n"
     ]
    }
   ],
   "source": [
    "# read in the pandas dataframe\n",
    "df = pd.read_csv('/home/nab/Niklas/TEM-lactamase/data/002_combined_data/TEM_lactamase.csv', sep=';')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we might pick two random sequences in our case the first two\n",
    "ids_list = df.iloc[0:2]['protein_id_database'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSIQHFRVALIPFFAAFCLPVFAHPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRVDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPAAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eedb.get_proteins(ids_list[0])[0]['p']['sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here i want to ge the blosum62 matrix and theri value as a matrix for a sequence\n",
    "# each sequence is compared with itself resulting in a square matrix\n",
    "\n",
    "# load in the blosum62 matrix\n",
    "# load in the blosum62 matrix\n",
    "blosum62 = pd.read_csv('/home/nab/Niklas/TEM-lactamase/data/blosum62.csv', sep=';')\n",
    "\n",
    "# Convert the string of values into a proper matrix\n",
    "# First, get the amino acid labels from the first column\n",
    "amino_acids = [row.split(',')[0] for row in blosum62.iloc[:, 0]]\n",
    "\n",
    "# Create the matrix by splitting the strings and converting to numbers\n",
    "matrix_values = []\n",
    "for row in blosum62.iloc[:, 0]:\n",
    "    # Split the row and convert to integers, skipping the first element (amino acid label)\n",
    "    values = [int(x) for x in row.split(',')[1:]]\n",
    "    matrix_values.append(values)\n",
    "\n",
    "# Convert to numpy array for easier manipulation\n",
    "blosum62_matrix = np.array(matrix_values)\n",
    "\n",
    "# Create a dictionary for easy lookup\n",
    "blosum_dict = {}\n",
    "for i, aa1 in enumerate(amino_acids):\n",
    "    for j, aa2 in enumerate(amino_acids):\n",
    "        blosum_dict[(aa1, aa2)] = blosum62_matrix[i, j]\n",
    "\n",
    "# Now you can calculate the comparison matrix for your sequences\n",
    "blosum62_matrix_comparison = []\n",
    "\n",
    "for i in range(len(ids_list)):\n",
    "    sequence = eedb.get_proteins(ids_list[i])[0]['p']['sequence']\n",
    "    matrix = np.zeros((len(sequence), len(sequence)))\n",
    "    \n",
    "    for j in range(len(sequence)):\n",
    "        for k in range(len(sequence)):\n",
    "            aa1 = sequence[j]\n",
    "            aa2 = sequence[k]\n",
    "            matrix[j, k] = blosum_dict.get((aa1, aa2), 0)\n",
    "    \n",
    "    blosum62_matrix_comparison.append(matrix)\n",
    "\n",
    "blosum62_matrix_comparison = np.array(blosum62_matrix_comparison)\n",
    "\n",
    "# make the comparison so that it is between 1 and 0\n",
    "blosum62_matrix_comparison = blosum62_matrix_comparison / np.max(blosum62_matrix_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "embeddings_single = np.array([et.calculate_single_sequence_embedding(eedb.get_proteins(id)[0]['p']['sequence']) for id in ids_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286, 1280)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_single[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 286, 286)\n"
     ]
    }
   ],
   "source": [
    "# cosine with itself\n",
    "cosine_similarity = np.array([et.calculate_similarity(embedding, embedding) for embedding in embeddings_single])\n",
    "print(cosine_similarity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mset_theme(style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhitegrid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_heatmap\u001b[39m(\n\u001b[1;32m      5\u001b[0m     matrix: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m      6\u001b[0m     title: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     vmax: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     16\u001b[0m ):\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Plot a heatmap of a similarity matrix.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m        target_ticks (list[str]): The ticks for the target sequence\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "def plot_heatmap(\n",
    "    matrix: np.ndarray,\n",
    "    title: str,\n",
    "    xlabel: str,\n",
    "    ylabel: str,\n",
    "    output_path: str,\n",
    "    figsize: tuple = (8, 8),\n",
    "    query_ticks: list[str] | None = None,\n",
    "    target_ticks: list[str] | None = None,\n",
    "    threshold: bool = True,\n",
    "    vmin: float = 0,\n",
    "    vmax: float = 1,\n",
    "):\n",
    "    \"\"\"Plot a heatmap of a similarity matrix.\n",
    "\n",
    "    Args:\n",
    "        matrix (np.ndarray): The similarity matrix to plot\n",
    "        output_path (str): The path to save the plot\n",
    "        figsize (tuple): The size of the figure\n",
    "        query_ticks (list[str]): The ticks for the query sequence\n",
    "        target_ticks (list[str]): The ticks for the target sequence\n",
    "    \"\"\"\n",
    "\n",
    "    _, ax1 = plt.subplots(1, 1, figsize=figsize)\n",
    "\n",
    "    if threshold:\n",
    "        matrix = np.where(\n",
    "            matrix < find_similarity_value_threshold(matrix, 10), 0, matrix\n",
    "        )\n",
    "\n",
    "    # Plot embedding-based heatmap\n",
    "    sns.heatmap(\n",
    "        matrix,\n",
    "        cmap=\"YlOrBr\",\n",
    "        annot=False,\n",
    "        ax=ax1,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "    ax1.set_title(title)\n",
    "    ax1.set_xlabel(xlabel)\n",
    "    ax1.set_ylabel(ylabel)\n",
    "\n",
    "    if query_ticks is not None:\n",
    "        ax1.tick_params(axis=\"x\", rotation=45)\n",
    "        ax1.set_xticks(np.arange(len(query_ticks)))\n",
    "        ax1.set_xticklabels(query_ticks)\n",
    "\n",
    "    if target_ticks is not None:\n",
    "        ax1.set_yticks(np.arange(len(target_ticks)))\n",
    "        ax1.set_yticklabels(target_ticks)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def find_similarity_value_threshold(matrix: np.ndarray, percentile: int):\n",
    "    \"\"\"Analyze the similarite and get the threshold of the 10% highest values.\n",
    "\n",
    "    Args:\n",
    "        matrix (np.ndarray): The similarity matrix\n",
    "    \"\"\"\n",
    "\n",
    "    return np.percentile(matrix, percentile).min()\n",
    "\n",
    "\n",
    "def plot_mean_similarity(\n",
    "    matrix: np.ndarray,\n",
    "    query_id: str,\n",
    "    output_path: str,\n",
    "):\n",
    "    \"\"\"Plot a bar plot of the mean similarity scores for each position in the query sequence.\n",
    "\n",
    "    Args:\n",
    "        matrix (np.ndarray): The similarity matrix\n",
    "        query_id (str): The id of the query sequence\n",
    "        output_path (str): The path to save the plot\n",
    "    \"\"\"\n",
    "\n",
    "    medians = [float(np.median(matrix[:, i])) for i in range(matrix.shape[1])]\n",
    "    positions = [i for i in range(matrix.shape[1])]\n",
    "\n",
    "    sns.lineplot(x=positions, y=medians)\n",
    "    plt.xlabel(f\"{query_id} Sequence Position\")\n",
    "    plt.ylabel(\"Median Similarity\")\n",
    "    plt.title(f\"Median Similarity per Position in {query_id}\")\n",
    "\n",
    "    # Add vertical lines and text for peaks below 0.20\n",
    "    for pos, median in zip(positions, medians):\n",
    "        if median < 0.1:\n",
    "            plt.axvline(x=pos, color=\"red\", linestyle=\"dotted\")\n",
    "            plt.text(pos, median, str(pos), color=\"red\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=200)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = '/home/nab/Niklas/TEM-lactamase/data/001_results/003_token_analysis'\n",
    "\n",
    "plot_heatmap(cosine_similarity[0], 'Cosine Similarity', 'Query Sequence', 'Target Sequence', f'{path_base}/cosine_similarity.png')\n",
    "plot_heatmap(blosum62_matrix_comparison[0], 'BLOSUM62 Similarity', 'Query Sequence', 'Target Sequence', f'{path_base}/blosum62_similarity.png', vmin=np.min(blosum62_matrix_comparison[0]), vmax=np.max(blosum62_matrix_comparison[0]))\n",
    "plot_mean_similarity(cosine_similarity[0], ids_list[0], f'{path_base}/mean_similarity.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyeed_niklas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
